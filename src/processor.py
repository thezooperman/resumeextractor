# /usr/bin/env python

import plac
import random
import string
from io import StringIO
import pathlib
import spacy
import json
from bs4 import BeautifulSoup
from spacy.util import compounding, minibatch

from fileop import FileOperation, walk_dir

# from spacy.matcher import Matcher

BASE_DIR = pathlib.Path.cwd()
MODEL_PATH = BASE_DIR / 'model'
printable = set(string.printable)
blacklisted_punctuation = {"'", '\\', '"'}

TRAIN_DATA = [
    ('Astajyoti Behera Business Analyst, Evalueserve Pvt. Ltd. Gurgaon, Haryana (M) +91-8010780053 Email: astajyoti@gmail.com Professional Summary Good exposure in business process modeling and developing statistical models using machine learning algorithms. Developed different statistical models for Regression , Classification , Segmentation and Forecasting problems. Good exposure in developing dashboards using Tableau . Proficient in working with R, Tableau, SQL and Excel. Developed a good understanding of Pharmacy, Retail and Consumer Health Care industry by working on different projects and assisting business leads in their various business needs With a total Experience of more than 2 years in an alytics domain, worked on projects including Clustering, Prediction, Classification, Forecasting, Sentiment Analysis, Data Management and various Sales reporting . Independently able to handle client with end to end solutions starting from requirement gathe ring to delivering the quality solution with optimal resource utilization. Proficient in designing the process flow for collecting information, managing it in a centralized location and perform different analysis on it. TECHNICAL PROFICIENCY Expertise in R to use different Machine Learning algorithms and automation Expertise in Tableau for reporting Good knowledge of SQL Server 2008 for processing & extracting data Proficient in MS Excel, its advanced features related to statistics, pivo ts and slicers. ACADEMIC QUALIFICATIONS & CERTIFICATION Degree Institute CGPA/Percentage Year of Passing M.E. Manufacturing System Eng. BITS, Pilani 9.44 2016 B.Tech. Mechanical Eng. Vel Tech University, Chennai 9.65 2013 C.H.S.E. (XII) U.N. College Soro, Odisha 80% 2009 H.S.E. (X) M.P.C. High School, Odisha 81% 2007 WORK EXPERIENCE Two years of experience in analytics in Pharmacy, Retail and Consumer Health Care industry. Three months of onsite experience in Europe Having experience in project management and consultant role Business Analyst, Evalueserve Pvt. Ltd. Gurgaon July 2016 Till date Business Analyst, Evalueserve Pvt. Ltd. Gurgaon July 2016 Till date Segmentation Analysis on Patient data: The objective was to understand the patient behavior so to have a enriched patient profile by having intelligent KPIs to gain insight on patient profiles The idea is to determine the important KPIs by performing Factor Analysis and clustering them into d ifferent groups using K-means clustering method Different groups are then segmented using the demographic data of the patients Forecasting of Pharma Sales data: Developed a tool for forecasting the pharma sales data using different time series analysis techniques Used Moving Average , Exponential Smoothing , Holtwinters , ets and ARIMA metho ds for determining the forecasted value Developed the tool in R using the packages forecast and PROPHET Social Media Analytics on different drugs: Performed Sentiment Analysis on different drugs and therapeutic areas to measure how positive or negative a person feels about the drugs Used the data from Twitter, Facebook and different blogs to extract the data and the subjective information to process it using Text Mining algorithms Product Grouping Automation: Developed a text classification models u sing Nave Bayes algorithm for automating the product categorization process This helps the stake holder to maintain more customizable groups in their products with the help of less resources Developed the model in R using the package H2O Data Management and Sales Reporting: Assisting Global Business Unit with data management needs using MS SQL based platform as database server for streamlining and simplifying the data historization and harmonization process Developed a Master Sales rep orting tool using Tableau to showcase all the relevant KPIs covering all the markets and their respective products This dashboard is being used globally for almost all the Sales based queries with real time data availability ACADEMIC DISTINCTIONS & ACHIEVEMENTS Have received the top performer and best team award in Evalueserve Pvt. Ltd. University gold medalist during bachelors in engineering Got scholarship consecutively for all semester during bachelors in engineering Have achieved top rating throughout the career Personal Information Present Address : C/1954, Second Floor, Sushant Lok - 1, Gurugram, Haryana - 122002 Date of Birth : 20 th June 1992 Fathers Name : Mr. Prasanta Behera Nationality : Indian Languages : English, Hindi and Oriya Reason for change : Quench for learning and further career growth, new roles and responsibilities', {"entities": [(0, 16, 'NAME'), (17, 33, 'DESG'), (57, 64, 'LOCATION'), (66, 73, 'LOCATION'), (79, 92, 'MOB'), (100, 119, 'EMAIL'), (447, 462, 'SKILLS'), (467, 472, 'SKILLS'), (1560, 1589, 'DEGREE'), (35, 55, 'Companies worked at')]}),
    ('Raghu Nanden (4.9 yrs Experience) Contact Email: raghunanden02@gmail.com City: Gurgaon (ready to relocate) Phone: +91-9599044124 Expertise Natural language processing (NLP),NLU, data science, machine learning, user modeling , computer vision, deep learning, artificial intelligence, python, graph database, predictive modeling EXPERIENCE Senior Data Scientist , Incedo , 2017-present Lead & developed client focused solutions tools by applying data science and artificial intelligence state of the art methods Interpret Knowledge Management Client: KBRA Developed a predictive relationship extraction module for a knowledge management system. Responsible for creating whole predictive modeling life-cycle i.e. data acquisition, baseline model building, exploratory data analysis, feature engineering, error analysis to model deployment in production. Developed a deep neural network model with the s tate-of-the-art macro-averaged F1 metric of 82 %. Applied machine learning, deep learning, GraphDB , text analysis to classify relationships in sentences. Chatbot ( Incedo cognitive framework) Client: Verizon, Tripwire, Vodafone Lead the data science team to build Incedo first chat bot conversation platform. Developed statistical machine learning model to anticipate user intentions to take actions. Responsible to lead data science team to create iterative life-cycle of user intent recognition system w ith 84% roc_auc_score . Implemented custom and pre-trained entity extraction models to extract entities from the text in chat Retrain the model to improve the quality of intent recognition. Applied machine learning, web scrapping, text analysis, statistical analysis to classify user intentions Advisor advice analysis Client: Incedo Developed an information extraction system to measure the quality of the stock market advisors recommendation based on analyzed success/failure rate of advisor. Applied machine learning and tactical information extraction techniques to extract required information from financial news website. Worked with business analyst to enhance the business use case of this analysis system. Software Engineer , Aon-Hewitt, 2014-2017 Developed solutions with focus on unstructured data from websites and the portals. Healthcare news clustering Client: Aon internal portal Developed unsupervised machine learning clustering model to segment different pharmaceutical news. Responsible for data acquisition from different websites. Determined the number of clusters by hierarchical clustering; used clustering and topic modeling algorithms i.e. Kmeans and LDA respectively to cluster news articles. Applied various text feature extraction techniques to improve the homogeneity score. Exposed it using flask API to find the topic of the news article. Healthcare package recommendation system Client: Aon Analytics Singapore Responsible for data cleaning operations extracted from dependent verification system database. Reported each data cleansing activity for each column of the data as directed by mentors. Applied data wrangling techniques using python and pandas. RESEARCH & OPEN SOURCE Open-Relationship-Extraction Framework : A machine learning & Deep Learning based development and error analysis framework for common relationship extraction. Pneumonia Detecti on System : Deep Learning based Pneumonia detection system from medical image of patient. 4betterW2V: Context aware word vectors based on deep Learning and machine learning techniques. Chat bot Intent Recognition : Research framework for data acquisition and modeling based to solve the semantic similarity & Natural Language Inference problem. CERTIFICATION Coursera certified Deep Learning specialist Upgrad Machine Learning course License: 8L2K2HLZEWX5 ACHEIVEMENTS Top 15 % in Kaggle RSNA Pneumonia Detection challenge. Domain: Medical, Computer vision Top 15% in Kaggle Two Sigma user interest prediction competition. Domain: Real Estate, Analytics 2 nd place in Aon Hackathon for sentiment analysis. Domain: NLP, text analysis SKILLS & TOOLS Python, keras , tensorflow , SKlearn , matplotlib , seaborn , pandas, numpy , statsmodel , linear regression,logistic regression, NLTK, Gensim , fasttext , Spacy ,decision trees, random forest, xgboost , deep neural networks, CNN, YOLO, RNN, LSTM, GRU, transfer learning, model evaluation, model selection, flask, restful API, sql , relational database, graph database, Neo4j. EDUCATION Bachelor of Engineering, May 2013 University: Panjab University Chandigarh', {"entities": [(0, 12, 'NAME'), (14, 21, 'Years of Experience'), (49, 72, 'EMAIL'), (79, 86, 'LOCATION'), (115, 128, 'MOB'), (4430, 4453,  'DEGREE'), (4043, 4418, 'SKILLS'), (338, 359, 'DESG'), (2122, 2139, 'DESG'), (362, 368, 'Companies worked at')]}),
    ('Sunil Kumar + 91 - 8860591559 | sun.kmr90@gmail.com | linkedin.com/in/skdhanrajani Work Experience Associate | Cognizant Technology Solutions | Aug 2015 to Present Gaps in Medical Coding Developing a Machine Learning algorithm to predict the likelihood of a Hierarchical Condition Category (HCC) based on existing and missing diagnosis codes Performed uni-variate and bivariate data exploration to develop variables required for developing the model. Performed data cleaning and pre processing to get the inputs for the data modeling phase. Tools Used: R, MS Excel Market Mix Modeling Led a team of 5 for analysis of channel promotion targeting incentive optimization for a pharmaceutical client Determine ROI of historical promotions for various promotional channels using Regression and Test Group- Control Group methodology. This also includes segmenting physicians based on Specialty and their prescription behaviour. Generated ROI curves for different marketing channels. Forecasted Revenue based on different spend allocation across promotional channels to enable Client to make informed decision. Provide optimal budget allocation scenarios for all channels for different brands using Greedy Algorithm. Tools Used: R, MS Excel and VBA Incentive Compe nsation Analytics for a leading Pharmaceutical Manufacturer Led offshore delivery team of 4 people for monthly time bound reports successfully Mentored and facilitated Knowledge transfer sessions for 5 new team members Sales Crediting of data through Structured Query Language to migrate data from client`s database Performed Impact Analysis across two Data Vendors to determine accuracy of data at Territory, District and Region level; Resulted in finalizing best data vendor for future requirements Autom ated a MS Excel manual report generation into a one click SQL oriented job Strategized dashboard designing for better business impact generation and appealing visuals to the end users with the help of MS Excel and embedded VBA scripts Tools Used: MS SQL, MS Excel & VBA Skills Technical: MS Excel, SQL, R, MS Power Point and elementary knowledge of tools like SAS, Python, etc. Education MBA in Business Economics | 2015 | Delhi University Majors: Quantitative Techniques in Business, Marketing Bachelor of Technology | 2012 | GTBIT, GGSIP University Major: Electrical and Electronics Engineering HSC, XII, Science | 2008 | CBSE SSC, X | 2006 | CBSE Internships Associate Producer - Research | Iamwire.com | May 2014 to July 2014 Conducted a holistic seconda ry research on E-commerce strategic model - technology, supply chain, marketing, and customer experience to Omni-channel retailing. Prepared an overall report covering the recommendations and suggestions for an E-commerce company Authored thoroughly researched articles for the publishing platform on Native advertising and Rakutens entry strategy in India in 2014. Projects and Papers Carried out a Primary Market Research and employed factor analysis to Identify the components t o evaluate the quality of E-commerce Logistics service (2015) Investigated the causality between Money Supply and Wholesale Price Index (WPI) using time series data (2014)', {"entities": [(0, 11, 'NAME'), (32, 51, 'EMAIL'), (14, 29, 'MOB'), (2153, 2168,  'DEGREE'), (2053, 2085, 'SKILLS'), (2012, 2034, 'SKILLS'), (2125, 2136, 'SKILLS'), (99, 108, 'DESG'), (111, 141, 'Companies worked at')]}),
    ('Priya Sancheti Gurgaon, India Contact Tel : +91 8800848151 e-mail : sanchetipriya0@gmail.com Objective Seeking a position that challenges & gives me opportunity to learn and contribute to organizations growth Education 2015 2013 MSc Mathematics, Miranda House, University of Delhi BSc. Mathematics, Miranda House, University of Delhi 83.13% 91.71% 2010 Sr. Secondary CBSE, K.S. Lodha Public School, Falna , Rajasthan 87% 2008 Secondary CBSE, K. S.Lodha Public School, Falna , Rajasthan 85.80 % Work Experience Decision Point Analytics, Gurgaon Oct, 2017 - Ongoing Business Analyst Price Statistic : Understood price evolution & momentum within industry over time to highlight white spaces across regions/channel for a beverage company. Share Estimation : Forecasted share across categories using statistical model viz VARMAX and highlighted potential shortfalls from the targets to make appropriate interventions. Contingency Planning: Studied correlation of Consumer Spends with various macro-economic variables and forecasted it using multivariate regression. Integrated Commercial Analytics: Utilized sales, production, competition and brand equity data to figure out various strategic and commercial opportunities. RED Impact : Analyzed impact of daily execution on sales using profiling, segmentation & quintile analysis. Decision Point Analytics, Gurgaon Oct, 2016 Oct, 2017 Data Analyst Growth Decomposition: Utilized growth decomposition framework to segment growth within same store universe. Developed, optimized & implemented store flag algorithm in SAS. Cannibalization: Analyzed the impact of new product launch on existing products for a beverage company in Central Asian Countries. Sales forecasting: Obtained volume trends & forecasted volume sales for various packs using ARIMA model for a beverage company. Automation: Automated routine deliverable to improve its efficiency by 33%. Academic Projects/ Courses Online Courses: Coursera Introduction to Data Science: a field that includes systems to extract insights from data. Statistics: Making sense of data , Using Statistical concepts to understand data. Fractals: Studied its nature and application in fields like Computer Graphics, Biology etc. Artificial Bee Colony (ABC Algorithm): Research study on natural behavioral of bees . Computational Skills Analytical and Statistical Tools: SAS | R | Advanced Excel Programming Languages: C++ | SQL Academic Achievements Awarded Kasturi Memorial Prize for securing the highest aggregate in BSc (H). Secured 2nd Position in Baseline Mathematical Science Test 2012-13, Miranda House. Awarded Gold Medal for securing 1 st position in 12 th standard science stream. Extra Curriculum Activities National Cadet Corps: Hold C Certificate as Junior Under Office with B- Grade. Department of Mathematics, Miranda House Served as Placement Cell Student Coordinator, 2012 13. Lead Paper Presentation event of ORIGIN 2013 department fest. Served as President, 2014 15 of Ananya Placement Cell, Department of Mathematics, DU.', {"entities": [(0, 14, 'NAME'), (68, 92, 'EMAIL'), (45, 58, 'MOB'), (15, 22, 'LOCATION'), (229, 244,  'DEGREE'), (2359, 2383, 'SKILLS'), (2407, 2416, 'SKILLS'), (510, 534, 'Companies worked at'), (564, 580, 'DESG'), (1381, 1393, 'DESG')]}),
    ('Dushyant Bhatt BI / Big Data/ Azure Hyderabad-Deccan, Telangana, Telangana - Email me on Indeed: indeed.com/r/Dushyant- Bhatt/140749dace5dc26f 10+ years of Experience in Designing, Development, Administration, Analysis, Management in the Business Intelligence Data warehousing, Client Server Technologies, Web-based Applications, cloud solutions and Databases. Data warehouse: Data analysis, star/ snow flake schema data modeling and design specific to data warehousing and business intelligence environment. Database: Experience in database designing, scalability, back-up and recovery, writing and optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake analytics(U-SQL). Big Data: Worked Azure data lake store/analytics for big data processing and Azure data factory to schedule U-SQL jobs. Designed and developed end to end big data solution for data insights. BI: o ETL: Designed and developed ETL solution in SSIS. Experience in Logging, Error handling, configuration, deployment, troubleshooting and performance tuning of SSIS Packages. o Reporting: Experience in all the Latest Reporting T ools like T ableau Data visualization, Power BI and SSRS 2012. Act as a Point of Contact in Data Interoperability, Analytics and BI and Production Support issue resolution. Experience in Developing Performance Dashboards, Score cards, Metrics, what if analysis, Prompts, Drills. Reports/Dashboards for all the functional areas including Finance, Pricing, Purchasing and Sales/Marketing. Willing to relocate: Anywhere WORK EXPERIENCE Software Engineer Microsoft - hyderbad, T elangana - December 2015 to Present 1. Microsoft Rewards Live dashboards: Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards live dashboards gives a live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations. the PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. T echnology/T ools used Event hub, stream analytics and Power BI. Responsibilities Created stream analytics jobs to process event hub dataCreated Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to show top/bottom 10 offers and usage metrics. 2. Microsoft Rewards Data Insights: Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards data insights is data analytics and reporting platform, processes 20 million users daily activities and redemption across different markets like US, Canada, Australia. T echnology/T ools used Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI. Responsibilities Created big data scripts in cosmos C# data extractors, processors and reducers for data transformation Power BI dashboards 3. End to end tracking T ool: Description: - This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE. It gives flexibility to customers to track their transactions and appropriate error information in-case of any failure. Based on resource based access control the tool gives flexibility to end user to perform different actions like view transactions, search based on different filter criteria and view and download actual message payload. End to end tracking tool stitches all the business transaction like order to cash flow and connects different hops inside ICOE like gateway, routing server, Processing server. It also connects different systems like ICOE, partner end point and SAP . T echnology/T ools used Azure Document db, Azure web job and Web APP, RBAC, Angular JS. Responsibilities Document dB stored procedures. Web job to process event hub data and populate Document db Web App API. Stream analytics job to transform data Power BI reports 4. Biztrack Tracking T ool: Description: - This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE. It gives flexibility to customers to track their transactions and appropriate error information in-case of any failure. Based on resource based access control the tool gives flexibility to end user to perform different actions like view transactions, search based on different filter criteria and view and download actual message payload. T echnology/T ools used SQL server 2014, SSIS, .net API, Angular JS. Responsibilities ETL solution to transform business transactions data stored in Biztalk tables. SQL azure tables, stored procedures, User defined functions. Performance tuning. Web API enhancements.EDUCATION Saurashtra University - Morbi, Gujarat 2007 SKILLS problem solving (Less than 1 year), project lifecycle (Less than 1 year), project manager (Less than 1 year), technical assistance. (Less than 1 year) ADDITIONAL INFORMATION Professional Skills Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills with ability to interact with individuals at all the levels Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments Positive attitude towards superiors &amp; peers Supervised junior developers throughout project lifecycle and provided technical assistance.', {"entities": [(0, 14, 'NAME'), (97, 142, 'EMAIL'), (36, 45, 'LOCATION'), (,,'DEGREE'), (143, 152, 'Years of Experience'), (1736, 1753,'DESG'), (1754, 1763, 'Companies worked at'), (5636, 5670, 'SKILLS'), (5672, 5708, 'SKILLS'), (5710, 5744, 'SKILLS'), (5746, 5786, 'SKILLS')]}),
    ('Ayush Kush Associate Business Analyst 3.8 years of experiences in analytics. Possess comprehensive knowledge of data science techniques (including data modeling, data mining, machine learning). ayushkush98@gmail.com 9130004283 Gurugram, India linkedin.com/in/ayush-kush-34930656 WORK EXPERIENCE 10/2014 Present Associate Business Analyst Infosys Ltd Worked for NGO Arpan- Infosys initiation child education. Participated & volunteer DC level Co-cultural & technical Fests. Managed the PMO level activities & communication for the Team. PROJECTS Contract Expiry Prediction (07/2018 Present) Developing an app to predict the expiry date as per the consumption of a particular contract for a manufacturing client of Europe Stock Prediction (01/2018 06/2018) Developed a dashboard to predict stock for next 3 month using time series analysis Social Media Analysis (09/2017 12/2017) Developed and provided analysis report for clients social media campaign. Downloaded the Images from Instagram, Facebook & provided the analysis by doing image processing. Email Classification (03/2017 08/2017) 5 Class Classification of incoming emails, for BPO team which includes from data fetching to data preparation. Accuracy of the model was 89.23% with high F1 score. SAP Roll out Project (01/2016 03/2017) Responsible for open transaction data migration, pre & post load validation, business sign-off & created reports for the migrated data. Created python tool to perform pre load validation of data & also designed dashboard for the Client verification. Created the template for Fixed Asset migration from legacy system to SAP. SAP FICO Support (05/2015 01/2016) Supported the business on day to day activity such as transaction, reporting,month end closing etc. Decreased the AR BPO tools error rate from 14% to 1.5%. EDUCATION Graduate Kurukshetra university. Electronics & communication-2013 SKILLS Data Analytics Data Modeling Machine Learning Python SQL SAP FICO SAP ABAP Tableau NoSQL Feature Selection Azure Cloud ACHIEVEMENTS Insta award (07/2017) Appreciated by clients for constant support and accountable work. (02/2016) CERTIFICATES Applied Machine Learning in Python (04/2018) Applied Plotting, Charting & Data Representation in Python (04/2018) Introduction to Data Science in Python (04/2018) ORGANIZATIONS Infosys Ltd (10/2014 Present) LANGUAGES English Hindi INTERESTS Reading Books Watching Videos Movie Achievements/Tasks Courses', {"entities": [(0, 10, 'NAME'), (196, 216, 'EMAIL'), (11, 36, 'DESIG'), (39, 47, 'Years of Experience'), (218, 227, 'MOB'), (229, 236, 'LOCATION'), (1853, 1879, 'DEGREE')]}),
    ('Shrey Shah Analytics & Decision Science Professional DESCRIPTION 3 years of analytics experience across digital ad-tech and retail customer engagement. Skilled at applying quantitative analyses, statistical models and machine learning on scale to solve business problems. Hometown Surat - 395009 Gujarat PHONE +91-95377-28145 EMAIL shahshrey93@gmail.com EXPERIENCE Sep-17 Ongoing Senior Business Analyst Dunnhumby Analytics Gurgaon Developed hierarchical predictive models to predict customers next purchase across 800+ categories for a retail store using a blend of logistic regression, random forest and GBM Developed Recommender System models based on collaborative filtering to predict likelihood of product acquisition at brand product family level Responsible for generating targeting algorithms, campaign measurement and management Solved campaign funding transparency issue by creating vendor dashboard in Tableau Sep-15 Sep-17 Decision Scientist Mu Sigma Analytics Bangalore Conceptualized a framework to define and track User Engagement for a leading content publishing website. Developed an Automated Power BI dashboard to monitor the same Led a team of three analysts to develop a competitor intelligence pipeline, with python web scraper and machine learning based (Nave Bayes Text Classifier in Azure ML) filter to pick most relevant articles Applied statistical modelling (Lasso Regression in R) to decode valuation of open market digital ads and used the same to benchmark performance of reserved ad placement Worked in a team of five to develop a strategy to mitigate the unsold inventory for a leading display advertising client, using Random forest regression in R to figure out feature importance and modelled Sell- Through-Rate as linear regression Worked on various automation using VBA Macro, PoweShell script SKILLSET High Proficiency: Python, PySpark, SQL, Excel, SCOPE for analyses Power BI, PowerPoint for visualization Hypothesis Testing, Design of Experiments, RegressionModelling, Decision Trees, Random Forest, Boosting, Bagging Intermediate Proficiency: R for analysis, VBA, PowerShell for automation Tableau for visualization RECOGNITION SPOT Award for creativity displayed in streamlining data flow and thereby reducing report development time by 80% EDUCATION NIT-Surat, B.Tech - Mechanical Engineering, CGPA 8.2', {"entities": [(0, 10, 'NAME'), (333, 353, 'EMAIL'), (312, 325, 'MOB'), (282, 286, 'LOCATION'),(1863, 1930, 'SKILLS'), (2089, 2142, 'SKILLS'), (2309, 2339, 'DEGREE')]}),
    ('Vaibhav Misra vaibhav6215@gmail.com; +91-8348522629 EDUCATION YEAR DEGREE/CERTIFICATE INSTITUTE CGPA/% 2011-2015 Bachelor of Technology(Honors) in Civil Engineering Indian Institute of Technology Kharagpur 7.88 2010-2011 Class XII: CBSE DAV Public School, Kota 90 % 2008-2009 Class X: CISCE Boys High School, Allahabad 96 % WORK EXPERIENCE PwC India, Gurgaon Experienced Consultant - Risk Assurance Services (Jan18-Present) Working with a top Indian payment tech/e-wallet company to ramp up their analytics practice Developed and implemented Predictive churn model using random forest algorithm to identify customers churning out probability from the platform Developing an uplift model to optimize the spend for user retention by modeling users tendency to respond to marketing campaigns ZS Associates, Gurgaon Business Operations Associate (Mar16-Jan18) Propensity to Buy Analysis: Account level cross-sell opportunity analysis for a leading global telecom provider which included identification of driving parameters, market opportunities and creating a cross-sell recommendation engine using k-nearest neighbors model developed in R Predictive churn analysis for a global telecom giant: Used historical data and developed models using classification and regression algorithms like random forests and logistic regression for identifying the accounts most likely to drop-off in the near future thereby allowing the company to take adequate measures for reducing the account churn rate in its global enterprise arm Market Research and Segmentation Study for a global tech giant: Study conducted across 6 countries for identifying segments that exist within the active online population for better targeting, identifying new opportunities and measuring brand loyalty in the market. Leveraged clustering techniques to identify the underlying segments with the surveyed sample from the population Demand forecasting for a leading south Asian airline: Using forecasting methods and other predictive models like regression, MARS and random forest to better estimate the future demand on the top 20 routes of the airline based on passenger traffic Sales model design and review for largest association of small businesses in the US: Using existing member and sales data for segmentation, account potentialization and better targeting of prospect members. Used decision trees for segmenting the member population Total Environment Building Systems, Bangalore Senior-Executive : Corporate Project Management Office (Jul15-Feb16) Prepared construction schedule for an upcoming multistory residential project. Prepared a Consolidated Project Tracker for mapping the progress of all the ongoing and proposed projects on a single dashboard PROJECTS & INTERNSHIP Avanti Learning Centres, New Delhi Intern Curriculum and operations team (May-July14) Worked with the Curriculum Team for developing a better suited curriculum for use with the Peer-Instruction Methodology Worked with the Operations team in setting up a new Avanti Centre in Gurgaon in collaboration with the Haryana State Education Board Larsen & Toubro Construction, New Delhi Intern Supply Chain and Procurement Office (May-Jun2013) Cost analysis on technical basis along with tax implication for selecting the appropriate vendor Added over 50 vendors in the existing database for the NCR region B.Tech Project, IIT Kharagpur Traffic Mode Choice Modeling using Artificial Neural Networks (Aug14-Apr15) Designed a predictive model using artificial neural networks for predicting the transportation choice of commuters based on demographic and trip data collected from a field survey in Kolkata Determined the major contributing parameters influencing commuters choice SKILLS Technical Skills R, SQL, Python, Advanced Excel, Power Point, Tableau, SPSS, Knowledge Seeker, Alteryx Analytical Skills Predictive Analytics, Customer Insights/Segmentation, Market Research, Data wrangling and visualization, Analytics project management, Building and operationalizing ML solutions', {"entities": [(0, 13, 'NAME'), (15, 35, 'EMAIL'), (39, 51, 'MOB'), (3748, 3805, 'SKILLS'), (3852, 4028, 'SKILLS'), (116, 166, 'DEGREE')]}),
    ('Sakshi Seth Female, Indian, 26 sakshiseth1109@gmail.com Ph. - 9916565965 Career Objective To obtain a challenging position in a reputed organization that would allow me to fully draw upon my academic knowledge, hone my skills and to help the organization achieve success concomitant with my personal development Work Experience 1. Senior Analyst (Business Analyst) dunnhumby TESCOUK (Apr17 till date) Client deliverables Responsible for timely delivery of client-ready presentation and additional insights for digital campaigns run via various social media partners like Sociomantic, Facebook, KBM and Twitter Delivered an average of 3+ campaign measurement decks and 4+ targetings per week across various markets and business partners Worked on multi-channel measurement of multiple retailer level campaigns along with client leads and i- store customer engagement counterparts Solutions development & enhancement Improved existing digital campaign targeting and evaluation solutions by taking feedback from analysts Developed a new Light Touch Solution to measure campaign performance for targeted households by enhancing the logic and bringing down the solution run time from 3 days to 2 hours Developed an exposure data ingestion engine which ingests huge chunks of data on daily basis and flags anomalies to the concerned team at the very first stage Recently took an additional responsibility of migrating solutions from SAS/SQL toPyspark/Hadoop in 3 sprints Achievements Was honored with a recognition award PayItForward for being instrumental in managing 8-10 projects simultaneously under stringent timelines 2. Decision Scientist (Business Analyst) Mu-Sigma Business Solutions (May15 Mar17) Worked for the Global web analytics team and drew valuable insights which further increased customer engagement for one of the top 20 Fortune-500 companies Built a world listening engine to capture worldwide trends & news topics and identify engaged users Currently working in a 4 member team on an open-ended organizational initiative to enable companies provide hyper-personalized offerings by monetizing trans-firewall data Formulated and implemented a detailed project plan for an open-ended organizational initiative Created an ultra-rich longitudinal customer behavior and preference database from their social media accounts Developed machine learning algorithms to learn and predict customer behavior Built an algorithm that identified 150,000 millennials on Twitter using machine learning concepts, mapping their behavior to personalized offerings Leveraged natural language processing tools to understand user behavior and used machine learning techniques to identify and tag millennials Created a graph database of millennials and their network, along with their interests and behavior to enable hyper-personalization Achievements - Successfully completed the project World Listening Engine in the given time & it has since been adopted by the organization 3. Intern at AGC Networks Avaya Global Connect (Jun 14 Jul14) To implement Project management tenants by managing, supervising and coordinating the roll-out of VoIP (Voice over Internet Protocol). Acted as an advisor in the six sigma implementation of message transmission so as to cut down on the cost for the organization Technical Skills Analytical Tools : SQL and SAS Programming Languages : Python and R Software : MS-Excel, Neo4j and Tableau Language proficiency : English, Hindi and basics of French Operating system : Windows, Linux (basic)Sakshi Seth Female, Indian, 26 sakshiseth1109@gmail.com Ph. - 9916565965 Academic Background Bachelors degree in Electronics and Communications Engineering Birla Institute of Technology (Aug11 May15) Projects / Training / Workshop 1. Successfully completed training at Mu Sigma University well within the stipulated time frame (May15 - Jun15) 2. Final year college projects (Aug14 Apr15) a. Developed a drowsy driver detection (D-3 tool) to identify and inform the concerned authorities if a driver is not in a condition to handle vehicle and thus prevent some major accidents before hand b. Implemented Human Computer Interface(HCI system) by making the computer understand and utilize human hand gestures and perform tasks accordingly Academic Achievements & Distinctions / Cultural / Sports Academic Achievements Secured AIR-479 in 11th National IT Aptitude Test (NITAT-2015) by scoring 99 percentile Was awarded first prize in HR Simulator (Management Team Event), Tech Vibes15 at Birla Institute of Technology Was selected to represent school in district level Biology Olympiad held by Delhi Public School, Agra Cultural Won first prize several times in Skit, Poetry and Group Singing Competitions at school level Was awarded silver medal for S.U.P.W. Sports Won second prize in district level (Moon Olympics) Basketball Tournament Won first prize in college level Throw ball, Kho-Kho and Volleyball Competition, Cavorts Extra-Curricular Activities Positions of Responsibility Youngest Core Team Representative Co-ordinated the companys Annual Cultural Event(Expos-2015) at Mu-Sigma Business Solutions Senior Coordinator of Cultural Committee Served as the Head Coordinator of the cultural committee Successfully organized the Annual cultural Fest Vibrations and the Annual Cultural Meet for four consecutive years Annual Technical Fest Volunteered for the Technical Committee of the college for 1 term and actively contributed in organizing Tech-Vibes (Annual Technical Fest) Model United Nations Represented college for two terms at Model United Nations (JECRC, Jaipur and IIT-Delhi) as the delegate of Cameroon and Angola in separate events I certify that the information furnished above is factually correct. (Sakshi Seth) Date- 10 Nov18', {"entities": [(0, 11, 'NAME'), (32, 55, 'EMAIL'), (63, 72, 'MOB'), (333, 346, 'DESIG'), (3332, 3342, 'SKILLS'), (3368, 3379, 'SKILLS'), (3392, 3418, 'SKILLS'), (3613, 3674, 'DEGREE')]}),
    ('Natalie M. Olivo github.com/nmolivo | nmolivo@gmail.com | medium.com/@NatalieOlivo I am a meticulous and incisive insight-finder, a dynamic collaborator, and a life-long learner. I have an aptitude for technical challenges, and with my experience in applied mathematics and training in data science, I bring a determined vivacity to each step of the problem-solving process, bringing grand visions to life. Professional Experience Student, GENERAL ASSEMBLY, Data Science Immersive Bootcamp October 2017 December 2017 Project-based training program that focuses on statistics, data analysis and visualization, and machine learning. SAT Participation Case Study: Exploratory data analysis and hypothesis testing; focus on data-driven action. Liquor Sales in Iowa: Linear models to predict sales, evaluation of model performance, regularization techniques. Going Viral on Reddit: Web Scraping and supervised, unsupervised, tree-based classification models. Preventing West Nile Virus: Geospatial data evaluation and XGBoost model; 81% accuracy on Kaggle. Drive business insights from text data: Use of Twitter API, AWS, Natural Language Processing, and Latent Dirichlet Allocation Topic Modeling; formal presentation of results to stakeholders. Actuarial Contractor, LYNCHVAL SYSTEMS WORLDWIDE, Washington, DC. March 2017 March 2018 The Pension Benefits Guarantee Corporation (PBGC) Worked on client site with a team to deliver an annual data scraping, collecting, and reasonability checking process to update a database which will be used to project future Pension Insurance performance. Over the span of 15 weeks, utilized the Department of Labor Form 5500 website, Visual Basic Macros, MS Excel, and proprietary software to create a database for 450 single-employer plans and 250 multi-employer plans. Automated a number of checking and reasonability processes by writing Visual Basic macros and teaching team members how to use and modify them, shaving a days work off of each week of the project. Consistently reached deadlines early to assist with managerial tasks and big-picture reasonability checking. Advanced to manager of a pricing trial for an initiative correcting and amending historical multi- and single- employer plan data. Actuarial Analyst, WILLIS TOWERS WATSON, Boston, MA. July 2013 June 2016 Engineered plan-specific spreadsheets and macros to produce bulk benefit calculations for bulk lump sum offerings and accrued benefit computations. Analyzed and implemented proprietary models for pension valuation per PPA, PBGC and ASC guidelines. Conduced non-discrimination testing with assumptions in accordance with government regulations. Served as internal office resource and mentor in preparing government forms and using new submission software. Facilitated intern and new-hire on-boarding by conducting interviews and leading Microsoft Excel trainings. Technologies & Skills Languages & Applications: Python, SQL, R, Excel, VBA, Tableau, HTML, CSS Methodologies: Analysis and visualization, Machine learning, time series modeling, Natural language processing, Statistical Modeling, Bayesian Networks, Neural Networks Education & Certifications GEORGE WASHINGTON UNIVERSITY, Washington, DC July 2016 December 2016 Graduate coursework in Data Science, International Trade, and Economics. GPA 3.67/4.0. BALL STATE UNIVERSITY, Muncie, IN May 2013 Bachelor of Science in Actuarial Science with Honors, Minor in Foundations of Business. GPA 3.6/4.0 SOCIETY OF ACTUARIES Passed two actuarial exams on financial mathematics and probability/statistics topics. Completion of Validation by Educational Experience Requirements (VEEs)', {"entities": [(0, 16, 'NAME'), (39, 55, 'EMAIL'), (2925, 3139, 'SKILLS')]}),
    ('Contact +918884404883 (Mobile) joy.calcutta@gmail.com www.linkedin.com/in/ghosharitra (LinkedIn) Top Skills Python Distributed Applications Cloud Computing Languages English (Full Professional) Bengali (Native or Bilingual) Hindi (Limited Working) Certifications SCJP Honors-Awards Excellence Awards Aritra Ghosh Distributed System | Full Stack | Dev-Ops | Architect Bengaluru, Karnataka, India Summary # Software engineer, with 12+ years of end-to-end software delivery # Customer obsessed Experience KPMG Development Lead March 2018 - Present Bengaluru Area, India Microsoft SDE II January 2016 - March 2018 (2 years 3 months) Hyderabad Area, India Building a PaaS based HR Data Insight product, using Microsoft Azure. # Azure Event Hub for large scale data processing # Micro-services on Azure Service Fabric # Azure Data Lake Store and Azure Data Lake Analytics for Big Data processing and data insights # Cortana Intelligence Suite for data insights Nasdaq Software Developer Specialist November 2014 - January 2016 (1 year 3 months) Bangalore #Built on Nasdaq Investor Relation Intelligence product suite #Built new modules - Event and Meetings #Built security mechanisms to prevent any injection attacks from user inputs #Tech Stack used - AngularJS, SQL, ASP.NET Web API, AWS Infosys Technology Lead Page 1 of 3 April 2012 - November 2014 (2 years 8 months) Working as a Techology Lead - current role includes technical suggestions and technical know how of the project and solutioning. Other activites involve client engagement, business requirement analysis, project delivery, goal oriented analysis and effort. HCL Technologies Lead Engineer June 2010 - March 2012 (1 year 10 months) Kolkata Area, India I work as a Lead Engineer in HCL Technologies. Currently I am in a project for Citi Singapore, it is a Winform based project, which uses a cheque scanner and processes business flows based upon input from that scanner, it also has a custom workflow and reporting module. I look after the Windows Sevices module and some of the windows interface module in this project. IBM India Pvt. Ltd System Engineer April 2006 - June 2010 (4 years 3 months) Worked as System Engineer, implementing projects for IBM India, job responsibilities included gathering requirements, verifying and validating the requirements and developing it maintaining IBMs RUP methodology. Apart from that was actively involved in writing test cases and executing test plans. Saregama India Ltd Associate System Executive September 2006 - February 2007 (6 months) Customer: Saregama India Limited Technology Platform: SAP, Windows XP Role: SD Module Implementer Aritra has worked in implementing the Sales &amp; Distribution module for SIL with support from SIEMENS India. Education Calcutta University Master in Computer Applications, Computer Applications (2003 - 2006) BIMS Page 2 of 3 Bachelor of Computer Applications, Computer Applications (2000 - 2003) Lycee (1985 - 1998) Page 3 of 3', {"entities": [(301, 312, 'NAME'), (32, 53, 'EMAIL'), (109, 155, 'SKILLS'), (10, 21, 'MOB'), (406, 421, 'DESIG'), (2789, 2819, 'DEGREE')]}),
    ('Contact +918600994960 (Mobile) dutta.83@gmail.com www.linkedin.com/in/siddhartha- dutta-107b567 (LinkedIn) siddsown.blogspot.com (Blog) Top Skills Market Data Corporate Finance Fixed Income Languages Bengali English Hindi Certifications Global Certification on Financial Markets Siddhartha Dutta Vice President at Credit Suisse Pune, Maharashtra, India Summary Heading Finance Data Quality and Change Management functions for Accounting and Basel capital reporting. Also includes team to support New Business onboarding for Credit Risk calculations. Experience Credit Suisse 7 years 6 months Vice President January 2019 - Present Pune, Maharashtra, India Assistant Vice President January 2015 - December 2018 (4 years) Pune Area, India Senior Accounting Specialist August 2011 - December 2014 (3 years 5 months) Deutsche Bank Senior Reference Data Analyst May 2010 - July 2011 (1 year 3 months) Thomson Reuters Data & Systems Specialist October 2009 - May 2010 (8 months) Reuters Senior Market Analyst July 2007 - September 2009 (2 years 3 months) Reuters Data Support Analyst May 2006 - June 2007 (1 year 2 months) Page 1 of 2 Education Symbiosis Institute of Business Management Master of Business Administration (M.B.A.), Finance, General (2014 - 2015) University of Calcutta M.Com, International Finance (2003 - 2005) Institute of Chartered Accountants of India CA (Inter), Accounts, Audit, Tax Laws (2003 - 2005) Bhawanipur Education Society College B.Com, Accounts, Finance (2000 - 2003) Bhawanipur Education Society College Higher Secondary, Commerce (1998 - 2000) Page 2 of 2', {"entities": [(280, 295, 'NAME'), (32, 49, 'EMAIL'), (148, 189, 'SKILLS'), (10, 21, 'MOB'), (297, 310, 'DESIG'), (1182, 1214, 'DEGREE')]})
]


def strip_html(content):
    soup = BeautifulSoup(content, features='lxml')
    return soup.get_text()


def clean_text(text):
    return ''.join([c for c in text if c in printable and c not in blacklisted_punctuation])


def test_read():
    try:
        for f in walk_dir():
            fileOp = FileOperation(f)
            sb = StringIO()
            suffix = f.split('.')[1]
            if suffix in ('docx', 'doc'):
                pass
                sb.write(' '.join([clean_text(line) for line
                                   in fileOp.read_docx()]))
                print(f'File Name: {f}')
                print('*' * 60)
                print()
            elif suffix == 'pdf':
                sb.write(''.join([clean_text(strip_html(line)) for line
                              in fileOp.read_pdf()]))
                print(f'File Name: {f}')
                print('*' * 60)
            print(sb.getvalue().strip())
            print()
    finally:
        if sb:
            sb.close()


def convert_dataturks_to_spacy(dataturks_JSON_FilePath):
    try:
        training_data = []
        lines=[]
        with open(dataturks_JSON_FilePath, 'r') as f:
            lines = f.readlines()

        for line in lines:
            data = json.loads(line)
            text = clean_text(strip_html(data['content']))
            entities = []
            for annotation in data['annotation']:
                #only a single point in text annotation.
                point = annotation['points'][0]
                labels = annotation['label']
                # handle both list of labels or a single label.
                if not isinstance(labels, list):
                    labels = [labels]

                for label in labels:
                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)
                    entities.append((point['start'], point['end'] + 1 ,label))
            training_data.append((text, {"entities" : entities}))
        return training_data
    except Exception as e:
        print("Unable to process " + dataturks_JSON_FilePath + "\n" + "error = " + str(e))
    return None


@plac.annotations(
    model=("Model name. Defaults to blank 'en' model.", "option", "m", str),
    output_dir=("Optional output directory", "option", "o", pathlib.Path),
    n_iter=("Number of training iterations", "option", "n", int),
)

def main(model=None, output_dir=None, n_iter=100):
    """Load the model, set up the pipeline and train the entity recognizer."""
    if model is not None:
        nlp = spacy.load(model)  # load existing spaCy model
        print("Loaded model '%s'" % model)
    else:
        nlp = spacy.blank("en")  # create blank Language class
        print("Created blank 'en' model")

    # create the built-in pipeline components and add them to the pipeline
    # nlp.create_pipe works for built-ins that are registered with spaCy
    if "ner" not in nlp.pipe_names:
        ner = nlp.create_pipe("ner")
        nlp.add_pipe(ner, last=True)
    # otherwise, get it so we can add labels
    else:
        ner = nlp.get_pipe("ner")

    TRAIN_DATA.extend(convert_dataturks_to_spacy(BASE_DIR / 'train_data' / 'traindata.json'))
    # add labels
    for _, annotations in TRAIN_DATA:
        for ent in annotations.get("entities"):
            ner.add_label(ent[2])

    if model is None:
        optimizer = nlp.begin_training()
    else:
        # Note that 'begin_training' initializes the models, so it'll zero out
        # existing entity types.
        optimizer = nlp.entity.create_optimizer()

    # get names of other pipes to disable them during training
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "ner"]
    with nlp.disable_pipes(*other_pipes):  # only train NER
        # reset and initialize the weights randomly – but only if we're
        # training a new model
        if model is None:
            nlp.begin_training()
        for _ in range(20):
            random.shuffle(TRAIN_DATA)
            losses = {}
            # batch up the examples using spaCy's minibatch
            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))
            for batch in batches:
                texts, annotations = zip(*batch)
                nlp.update(
                    texts,  # batch of texts
                    annotations,  # batch of annotations,
                    sgd=optimizer,
                    drop=0.35,  # dropout - make it harder to memorise data
                    losses=losses,
                )
            print("Losses", losses)

    # test the trained model
    test_data = []
    for f in walk_dir():
        fileOp = FileOperation(f)
        sb = StringIO()
        suffix = f.split('.')[1]
        if suffix == 'pdf':
            sb.write(''.join([clean_text(strip_html(line)) for line in fileOp.read_pdf()]))
            test_data.append(sb.getvalue().strip())
            sb.close()
    # for text, _ in TRAIN_DATA:
    for text in test_data:
        doc = nlp(text)
        print("Entities", [(ent.text, ent.label_) for ent in doc.ents])
    # print("Tokens", [(t.text, t.ent_type_, t.ent_iob) for t in doc])

    # save model to output directory
    if output_dir is not None:
        output_dir = BASE_DIR / output_dir #pathlib.Path(output_dir)
        if not output_dir.exists():
            output_dir.mkdir()
        nlp.to_disk(output_dir)
        print("Saved model to", output_dir)

        # test the saved model
        print("Loading from", output_dir)
        nlp2 = spacy.load(output_dir)
        for text, _ in TRAIN_DATA:
            doc = nlp2(text)
            print("Entities", [(ent.text, ent.label_) for ent in doc.ents])
            # print("Tokens", [(t.text, t.ent_type_, t.ent_iob) for t in doc])

    # for f in walk_dir():
    #     fileOp = FileOperation(f)
    #     sb = StringIO()
    #     suffix = f.split('.')[1]
    #     if suffix in ('docx', 'doc'):
    #         pass
    #         sb.write(' '.join([clean_text(line) for line
    #                            in fileOp.read_docx()]))
    #         print(f'File Name: {f}')
    #         print('*' * 60)
    #         print()
    #     elif suffix == 'pdf':
    #         sb.write(''.join([clean_text(strip_html(line)) for line
    #                       in fileOp.read_pdf()]))
    #         print(f'File Name: {f}')
    #         print('*' * 60)
    #     print(sb.getvalue().strip())
    #     print()
    #     sb.close()



if __name__ == '__main__':
    plac.call(main)
    # test_read()
